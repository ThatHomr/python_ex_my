{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_df = pd.read_csv('./santander_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39205.17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49278.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "0   1     2     23                 0.0                      0.0   \n",
       "1   3     2     34                 0.0                      0.0   \n",
       "\n",
       "   imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "\n",
       "   imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  ...  \\\n",
       "0                      0.0                      0.0  ...   \n",
       "1                      0.0                      0.0  ...   \n",
       "\n",
       "   saldo_medio_var33_hace2  saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
       "0                      0.0                      0.0                     0.0   \n",
       "1                      0.0                      0.0                     0.0   \n",
       "\n",
       "   saldo_medio_var33_ult3  saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "0                     0.0                      0.0                      0.0   \n",
       "1                     0.0                      0.0                      0.0   \n",
       "\n",
       "   saldo_medio_var44_ult1  saldo_medio_var44_ult3     var38  TARGET  \n",
       "0                     0.0                     0.0  39205.17       0  \n",
       "1                     0.0                     0.0  49278.03       0  \n",
       "\n",
       "[2 rows x 371 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 76020 entries, 0 to 76019\n",
      "Columns: 371 entries, ID to TARGET\n",
      "dtypes: float64(111), int64(260)\n",
      "memory usage: 215.2 MB\n"
     ]
    }
   ],
   "source": [
    "cust_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                         0\n",
       "imp_trasp_var17_in_ult1    0\n",
       "ind_var7_emit_ult1         0\n",
       "imp_venta_var44_ult1       0\n",
       "imp_venta_var44_hace3      0\n",
       "                          ..\n",
       "num_op_var40_hace3         0\n",
       "num_op_var40_hace2         0\n",
       "num_var25                  0\n",
       "num_var25_0                0\n",
       "TARGET                     0\n",
       "Length: 371, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_df.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    73012\n",
       "1     3008\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_df['TARGET'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0395685345961589"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "un_cnt = cust_df[cust_df['TARGET'] == 1].TARGET.count()\n",
    "total_cnt = cust_df.TARGET.count()\n",
    "\n",
    "un_cnt/total_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>76020.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>75964.050723</td>\n",
       "      <td>-1523.199277</td>\n",
       "      <td>33.212865</td>\n",
       "      <td>86.208265</td>\n",
       "      <td>72.363067</td>\n",
       "      <td>119.529632</td>\n",
       "      <td>3.559130</td>\n",
       "      <td>6.472698</td>\n",
       "      <td>0.412946</td>\n",
       "      <td>0.567352</td>\n",
       "      <td>...</td>\n",
       "      <td>7.935824</td>\n",
       "      <td>1.365146</td>\n",
       "      <td>12.215580</td>\n",
       "      <td>8.784074</td>\n",
       "      <td>31.505324</td>\n",
       "      <td>1.858575</td>\n",
       "      <td>76.026165</td>\n",
       "      <td>56.614351</td>\n",
       "      <td>1.172358e+05</td>\n",
       "      <td>0.039569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>43781.947379</td>\n",
       "      <td>39033.462364</td>\n",
       "      <td>12.956486</td>\n",
       "      <td>1614.757313</td>\n",
       "      <td>339.315831</td>\n",
       "      <td>546.266294</td>\n",
       "      <td>93.155749</td>\n",
       "      <td>153.737066</td>\n",
       "      <td>30.604864</td>\n",
       "      <td>36.513513</td>\n",
       "      <td>...</td>\n",
       "      <td>455.887218</td>\n",
       "      <td>113.959637</td>\n",
       "      <td>783.207399</td>\n",
       "      <td>538.439211</td>\n",
       "      <td>2013.125393</td>\n",
       "      <td>147.786584</td>\n",
       "      <td>4040.337842</td>\n",
       "      <td>2852.579397</td>\n",
       "      <td>1.826646e+05</td>\n",
       "      <td>0.194945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-999999.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.163750e+03</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>38104.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.787061e+04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>76043.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.064092e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>113748.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.187563e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>151838.000000</td>\n",
       "      <td>238.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>210000.000000</td>\n",
       "      <td>12888.030000</td>\n",
       "      <td>21024.810000</td>\n",
       "      <td>8237.820000</td>\n",
       "      <td>11073.570000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50003.880000</td>\n",
       "      <td>20385.720000</td>\n",
       "      <td>138831.630000</td>\n",
       "      <td>91778.730000</td>\n",
       "      <td>438329.220000</td>\n",
       "      <td>24650.010000</td>\n",
       "      <td>681462.900000</td>\n",
       "      <td>397884.300000</td>\n",
       "      <td>2.203474e+07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID           var3         var15  imp_ent_var16_ult1  \\\n",
       "count   76020.000000   76020.000000  76020.000000        76020.000000   \n",
       "mean    75964.050723   -1523.199277     33.212865           86.208265   \n",
       "std     43781.947379   39033.462364     12.956486         1614.757313   \n",
       "min         1.000000 -999999.000000      5.000000            0.000000   \n",
       "25%     38104.750000       2.000000     23.000000            0.000000   \n",
       "50%     76043.000000       2.000000     28.000000            0.000000   \n",
       "75%    113748.750000       2.000000     40.000000            0.000000   \n",
       "max    151838.000000     238.000000    105.000000       210000.000000   \n",
       "\n",
       "       imp_op_var39_comer_ult1  imp_op_var39_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                 72.363067               119.529632   \n",
       "std                 339.315831               546.266294   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               12888.030000             21024.810000   \n",
       "\n",
       "       imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  3.559130                 6.472698   \n",
       "std                  93.155749               153.737066   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max                8237.820000             11073.570000   \n",
       "\n",
       "       imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  ...  \\\n",
       "count             76020.000000             76020.000000  ...   \n",
       "mean                  0.412946                 0.567352  ...   \n",
       "std                  30.604864                36.513513  ...   \n",
       "min                   0.000000                 0.000000  ...   \n",
       "25%                   0.000000                 0.000000  ...   \n",
       "50%                   0.000000                 0.000000  ...   \n",
       "75%                   0.000000                 0.000000  ...   \n",
       "max                6600.000000              6600.000000  ...   \n",
       "\n",
       "       saldo_medio_var33_hace2  saldo_medio_var33_hace3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  7.935824                 1.365146   \n",
       "std                 455.887218               113.959637   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               50003.880000             20385.720000   \n",
       "\n",
       "       saldo_medio_var33_ult1  saldo_medio_var33_ult3  \\\n",
       "count            76020.000000            76020.000000   \n",
       "mean                12.215580                8.784074   \n",
       "std                783.207399              538.439211   \n",
       "min                  0.000000                0.000000   \n",
       "25%                  0.000000                0.000000   \n",
       "50%                  0.000000                0.000000   \n",
       "75%                  0.000000                0.000000   \n",
       "max             138831.630000            91778.730000   \n",
       "\n",
       "       saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                 31.505324                 1.858575   \n",
       "std                2013.125393               147.786584   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max              438329.220000             24650.010000   \n",
       "\n",
       "       saldo_medio_var44_ult1  saldo_medio_var44_ult3         var38  \\\n",
       "count            76020.000000            76020.000000  7.602000e+04   \n",
       "mean                76.026165               56.614351  1.172358e+05   \n",
       "std               4040.337842             2852.579397  1.826646e+05   \n",
       "min                  0.000000                0.000000  5.163750e+03   \n",
       "25%                  0.000000                0.000000  6.787061e+04   \n",
       "50%                  0.000000                0.000000  1.064092e+05   \n",
       "75%                  0.000000                0.000000  1.187563e+05   \n",
       "max             681462.900000           397884.300000  2.203474e+07   \n",
       "\n",
       "             TARGET  \n",
       "count  76020.000000  \n",
       "mean       0.039569  \n",
       "std        0.194945  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 371 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 2         74165\n",
       " 8           138\n",
       "-999999      116\n",
       " 9           110\n",
       " 3           108\n",
       "           ...  \n",
       " 231           1\n",
       " 188           1\n",
       " 168           1\n",
       " 135           1\n",
       " 87            1\n",
       "Name: var3, Length: 208, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_df.var3.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_df['var3'].replace(-999999,2,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2      74281\n",
       "8        138\n",
       "9        110\n",
       "3        108\n",
       "1        105\n",
       "       ...  \n",
       "231        1\n",
       "188        1\n",
       "168        1\n",
       "135        1\n",
       "87         1\n",
       "Name: var3, Length: 207, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_df.var3.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_df.drop(columns='ID', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cust_df.iloc[:,:-1]\n",
    "y = cust_df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,\n",
    "                                                    y,\n",
    "                                                    train_size=0.2,\n",
    "                                                    random_state=0,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.960405\n",
       "1    0.039595\n",
       "Name: TARGET, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cnt = y_train.count()\n",
    "test_cnt = y_test.count()\n",
    "y_train.value_counts()/train_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.960438\n",
       "1    0.039562\n",
       "Name: TARGET, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()/test_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.82023\tvalidation_1-auc:0.80373\n",
      "[1]\tvalidation_0-auc:0.83499\tvalidation_1-auc:0.80603\n",
      "[2]\tvalidation_0-auc:0.84562\tvalidation_1-auc:0.81035\n",
      "[3]\tvalidation_0-auc:0.85415\tvalidation_1-auc:0.81384\n",
      "[4]\tvalidation_0-auc:0.86033\tvalidation_1-auc:0.81568\n",
      "[5]\tvalidation_0-auc:0.87061\tvalidation_1-auc:0.82070\n",
      "[6]\tvalidation_0-auc:0.87613\tvalidation_1-auc:0.82218\n",
      "[7]\tvalidation_0-auc:0.88336\tvalidation_1-auc:0.82352\n",
      "[8]\tvalidation_0-auc:0.89401\tvalidation_1-auc:0.82583\n",
      "[9]\tvalidation_0-auc:0.89730\tvalidation_1-auc:0.82543\n",
      "[10]\tvalidation_0-auc:0.90003\tvalidation_1-auc:0.82715\n",
      "[11]\tvalidation_0-auc:0.90557\tvalidation_1-auc:0.82647\n",
      "[12]\tvalidation_0-auc:0.91182\tvalidation_1-auc:0.82725\n",
      "[13]\tvalidation_0-auc:0.91466\tvalidation_1-auc:0.82758\n",
      "[14]\tvalidation_0-auc:0.91700\tvalidation_1-auc:0.82861\n",
      "[15]\tvalidation_0-auc:0.91982\tvalidation_1-auc:0.82835\n",
      "[16]\tvalidation_0-auc:0.92075\tvalidation_1-auc:0.82837\n",
      "[17]\tvalidation_0-auc:0.92497\tvalidation_1-auc:0.82845\n",
      "[18]\tvalidation_0-auc:0.92740\tvalidation_1-auc:0.82796\n",
      "[19]\tvalidation_0-auc:0.92823\tvalidation_1-auc:0.82778\n",
      "[20]\tvalidation_0-auc:0.92880\tvalidation_1-auc:0.82771\n",
      "[21]\tvalidation_0-auc:0.92931\tvalidation_1-auc:0.82758\n",
      "[22]\tvalidation_0-auc:0.92998\tvalidation_1-auc:0.82790\n",
      "[23]\tvalidation_0-auc:0.93022\tvalidation_1-auc:0.82795\n",
      "[24]\tvalidation_0-auc:0.93078\tvalidation_1-auc:0.82746\n",
      "[25]\tvalidation_0-auc:0.93158\tvalidation_1-auc:0.82760\n",
      "[26]\tvalidation_0-auc:0.93271\tvalidation_1-auc:0.82758\n",
      "[27]\tvalidation_0-auc:0.93348\tvalidation_1-auc:0.82677\n",
      "[28]\tvalidation_0-auc:0.93600\tvalidation_1-auc:0.82607\n",
      "[29]\tvalidation_0-auc:0.93631\tvalidation_1-auc:0.82594\n",
      "[30]\tvalidation_0-auc:0.93697\tvalidation_1-auc:0.82538\n",
      "[31]\tvalidation_0-auc:0.93731\tvalidation_1-auc:0.82527\n",
      "[32]\tvalidation_0-auc:0.93776\tvalidation_1-auc:0.82483\n",
      "[33]\tvalidation_0-auc:0.93816\tvalidation_1-auc:0.82495\n",
      "[34]\tvalidation_0-auc:0.93859\tvalidation_1-auc:0.82508\n",
      "[35]\tvalidation_0-auc:0.93916\tvalidation_1-auc:0.82455\n",
      "[36]\tvalidation_0-auc:0.94127\tvalidation_1-auc:0.82438\n",
      "[37]\tvalidation_0-auc:0.94162\tvalidation_1-auc:0.82407\n",
      "[38]\tvalidation_0-auc:0.94455\tvalidation_1-auc:0.82309\n",
      "[39]\tvalidation_0-auc:0.94500\tvalidation_1-auc:0.82293\n",
      "[40]\tvalidation_0-auc:0.94563\tvalidation_1-auc:0.82267\n",
      "[41]\tvalidation_0-auc:0.94804\tvalidation_1-auc:0.82224\n",
      "[42]\tvalidation_0-auc:0.94825\tvalidation_1-auc:0.82206\n",
      "[43]\tvalidation_0-auc:0.94868\tvalidation_1-auc:0.82166\n",
      "[44]\tvalidation_0-auc:0.95037\tvalidation_1-auc:0.82080\n",
      "[45]\tvalidation_0-auc:0.95230\tvalidation_1-auc:0.82041\n",
      "[46]\tvalidation_0-auc:0.95243\tvalidation_1-auc:0.82027\n",
      "[47]\tvalidation_0-auc:0.95361\tvalidation_1-auc:0.82039\n",
      "[48]\tvalidation_0-auc:0.95394\tvalidation_1-auc:0.82006\n",
      "[49]\tvalidation_0-auc:0.95580\tvalidation_1-auc:0.81920\n",
      "[50]\tvalidation_0-auc:0.95628\tvalidation_1-auc:0.81891\n",
      "[51]\tvalidation_0-auc:0.95641\tvalidation_1-auc:0.81898\n",
      "[52]\tvalidation_0-auc:0.95726\tvalidation_1-auc:0.81877\n",
      "[53]\tvalidation_0-auc:0.95753\tvalidation_1-auc:0.81791\n",
      "[54]\tvalidation_0-auc:0.95891\tvalidation_1-auc:0.81722\n",
      "[55]\tvalidation_0-auc:0.95915\tvalidation_1-auc:0.81678\n",
      "[56]\tvalidation_0-auc:0.95933\tvalidation_1-auc:0.81698\n",
      "[57]\tvalidation_0-auc:0.96085\tvalidation_1-auc:0.81639\n",
      "[58]\tvalidation_0-auc:0.96195\tvalidation_1-auc:0.81591\n",
      "[59]\tvalidation_0-auc:0.96374\tvalidation_1-auc:0.81523\n",
      "[60]\tvalidation_0-auc:0.96469\tvalidation_1-auc:0.81471\n",
      "[61]\tvalidation_0-auc:0.96535\tvalidation_1-auc:0.81439\n",
      "[62]\tvalidation_0-auc:0.96564\tvalidation_1-auc:0.81424\n",
      "[63]\tvalidation_0-auc:0.96676\tvalidation_1-auc:0.81356\n",
      "[64]\tvalidation_0-auc:0.96728\tvalidation_1-auc:0.81381\n",
      "[65]\tvalidation_0-auc:0.96785\tvalidation_1-auc:0.81362\n",
      "[66]\tvalidation_0-auc:0.96821\tvalidation_1-auc:0.81279\n",
      "[67]\tvalidation_0-auc:0.96951\tvalidation_1-auc:0.81260\n",
      "[68]\tvalidation_0-auc:0.97021\tvalidation_1-auc:0.81257\n",
      "[69]\tvalidation_0-auc:0.97110\tvalidation_1-auc:0.81211\n",
      "[70]\tvalidation_0-auc:0.97110\tvalidation_1-auc:0.81211\n",
      "[71]\tvalidation_0-auc:0.97202\tvalidation_1-auc:0.81148\n",
      "[72]\tvalidation_0-auc:0.97248\tvalidation_1-auc:0.81120\n",
      "[73]\tvalidation_0-auc:0.97309\tvalidation_1-auc:0.81061\n",
      "[74]\tvalidation_0-auc:0.97424\tvalidation_1-auc:0.81013\n",
      "[75]\tvalidation_0-auc:0.97422\tvalidation_1-auc:0.81009\n",
      "[76]\tvalidation_0-auc:0.97430\tvalidation_1-auc:0.80995\n",
      "[77]\tvalidation_0-auc:0.97439\tvalidation_1-auc:0.80991\n",
      "[78]\tvalidation_0-auc:0.97445\tvalidation_1-auc:0.80929\n",
      "[79]\tvalidation_0-auc:0.97448\tvalidation_1-auc:0.80916\n",
      "[80]\tvalidation_0-auc:0.97538\tvalidation_1-auc:0.80863\n",
      "[81]\tvalidation_0-auc:0.97559\tvalidation_1-auc:0.80842\n",
      "[82]\tvalidation_0-auc:0.97565\tvalidation_1-auc:0.80804\n",
      "[83]\tvalidation_0-auc:0.97571\tvalidation_1-auc:0.80783\n",
      "[84]\tvalidation_0-auc:0.97588\tvalidation_1-auc:0.80775\n",
      "[85]\tvalidation_0-auc:0.97598\tvalidation_1-auc:0.80750\n",
      "[86]\tvalidation_0-auc:0.97651\tvalidation_1-auc:0.80775\n",
      "[87]\tvalidation_0-auc:0.97658\tvalidation_1-auc:0.80765\n",
      "[88]\tvalidation_0-auc:0.97715\tvalidation_1-auc:0.80718\n",
      "[89]\tvalidation_0-auc:0.97732\tvalidation_1-auc:0.80753\n",
      "[90]\tvalidation_0-auc:0.97731\tvalidation_1-auc:0.80750\n",
      "[91]\tvalidation_0-auc:0.97732\tvalidation_1-auc:0.80737\n",
      "[92]\tvalidation_0-auc:0.97785\tvalidation_1-auc:0.80716\n",
      "[93]\tvalidation_0-auc:0.97788\tvalidation_1-auc:0.80683\n",
      "[94]\tvalidation_0-auc:0.97821\tvalidation_1-auc:0.80648\n",
      "[95]\tvalidation_0-auc:0.97823\tvalidation_1-auc:0.80624\n",
      "[96]\tvalidation_0-auc:0.97829\tvalidation_1-auc:0.80592\n",
      "[97]\tvalidation_0-auc:0.97881\tvalidation_1-auc:0.80570\n",
      "[98]\tvalidation_0-auc:0.97951\tvalidation_1-auc:0.80576\n",
      "[99]\tvalidation_0-auc:0.97978\tvalidation_1-auc:0.80530\n",
      "[100]\tvalidation_0-auc:0.97985\tvalidation_1-auc:0.80576\n",
      "[101]\tvalidation_0-auc:0.98011\tvalidation_1-auc:0.80583\n",
      "[102]\tvalidation_0-auc:0.98016\tvalidation_1-auc:0.80583\n",
      "[103]\tvalidation_0-auc:0.98020\tvalidation_1-auc:0.80567\n",
      "[104]\tvalidation_0-auc:0.98026\tvalidation_1-auc:0.80519\n",
      "[105]\tvalidation_0-auc:0.98028\tvalidation_1-auc:0.80495\n",
      "[106]\tvalidation_0-auc:0.98029\tvalidation_1-auc:0.80480\n",
      "[107]\tvalidation_0-auc:0.98032\tvalidation_1-auc:0.80451\n",
      "[108]\tvalidation_0-auc:0.98045\tvalidation_1-auc:0.80427\n",
      "[109]\tvalidation_0-auc:0.98081\tvalidation_1-auc:0.80398\n",
      "[110]\tvalidation_0-auc:0.98116\tvalidation_1-auc:0.80408\n",
      "[111]\tvalidation_0-auc:0.98142\tvalidation_1-auc:0.80350\n",
      "[112]\tvalidation_0-auc:0.98150\tvalidation_1-auc:0.80343\n",
      "[113]\tvalidation_0-auc:0.98173\tvalidation_1-auc:0.80306\n",
      "[114]\tvalidation_0-auc:0.98244\tvalidation_1-auc:0.80274\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=500, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=156, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=500, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=156, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=500, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=156, ...)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf = XGBClassifier(n_estimators=500,\n",
    "                        random_state = 156)\n",
    "xgb_clf.fit(x_train,\n",
    "            y_train,\n",
    "            early_stopping_rounds=100,\n",
    "            eval_metric='auc',\n",
    "            eval_set = [(x_train, y_train), (x_test, y_test)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "c:\\Users\\admin\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's auc: 0.831131\ttraining's binary_logloss: 0.156116\tvalid_1's auc: 0.806753\tvalid_1's binary_logloss: 0.15859\n",
      "[2]\ttraining's auc: 0.841419\ttraining's binary_logloss: 0.149456\tvalid_1's auc: 0.809716\tvalid_1's binary_logloss: 0.154058\n",
      "[3]\ttraining's auc: 0.847476\ttraining's binary_logloss: 0.144508\tvalid_1's auc: 0.811835\tvalid_1's binary_logloss: 0.150831\n",
      "[4]\ttraining's auc: 0.858618\ttraining's binary_logloss: 0.140522\tvalid_1's auc: 0.816859\tvalid_1's binary_logloss: 0.148392\n",
      "[5]\ttraining's auc: 0.865482\ttraining's binary_logloss: 0.137123\tvalid_1's auc: 0.820966\tvalid_1's binary_logloss: 0.146312\n",
      "[6]\ttraining's auc: 0.874482\ttraining's binary_logloss: 0.13435\tvalid_1's auc: 0.825903\tvalid_1's binary_logloss: 0.14463\n",
      "[7]\ttraining's auc: 0.883258\ttraining's binary_logloss: 0.131779\tvalid_1's auc: 0.825384\tvalid_1's binary_logloss: 0.143315\n",
      "[8]\ttraining's auc: 0.885795\ttraining's binary_logloss: 0.129655\tvalid_1's auc: 0.826886\tvalid_1's binary_logloss: 0.142237\n",
      "[9]\ttraining's auc: 0.887946\ttraining's binary_logloss: 0.127726\tvalid_1's auc: 0.827103\tvalid_1's binary_logloss: 0.141364\n",
      "[10]\ttraining's auc: 0.889685\ttraining's binary_logloss: 0.12602\tvalid_1's auc: 0.827436\tvalid_1's binary_logloss: 0.140634\n",
      "[11]\ttraining's auc: 0.891622\ttraining's binary_logloss: 0.124551\tvalid_1's auc: 0.826562\tvalid_1's binary_logloss: 0.140097\n",
      "[12]\ttraining's auc: 0.89391\ttraining's binary_logloss: 0.123215\tvalid_1's auc: 0.826375\tvalid_1's binary_logloss: 0.139555\n",
      "[13]\ttraining's auc: 0.897569\ttraining's binary_logloss: 0.121749\tvalid_1's auc: 0.827092\tvalid_1's binary_logloss: 0.139108\n",
      "[14]\ttraining's auc: 0.899654\ttraining's binary_logloss: 0.120542\tvalid_1's auc: 0.827054\tvalid_1's binary_logloss: 0.138765\n",
      "[15]\ttraining's auc: 0.903123\ttraining's binary_logloss: 0.119244\tvalid_1's auc: 0.826906\tvalid_1's binary_logloss: 0.138447\n",
      "[16]\ttraining's auc: 0.905874\ttraining's binary_logloss: 0.11812\tvalid_1's auc: 0.827044\tvalid_1's binary_logloss: 0.138162\n",
      "[17]\ttraining's auc: 0.908572\ttraining's binary_logloss: 0.116954\tvalid_1's auc: 0.827194\tvalid_1's binary_logloss: 0.13794\n",
      "[18]\ttraining's auc: 0.910151\ttraining's binary_logloss: 0.115826\tvalid_1's auc: 0.827297\tvalid_1's binary_logloss: 0.13768\n",
      "[19]\ttraining's auc: 0.91275\ttraining's binary_logloss: 0.114808\tvalid_1's auc: 0.828001\tvalid_1's binary_logloss: 0.137423\n",
      "[20]\ttraining's auc: 0.914817\ttraining's binary_logloss: 0.113891\tvalid_1's auc: 0.827699\tvalid_1's binary_logloss: 0.1373\n",
      "[21]\ttraining's auc: 0.916327\ttraining's binary_logloss: 0.113008\tvalid_1's auc: 0.828166\tvalid_1's binary_logloss: 0.137116\n",
      "[22]\ttraining's auc: 0.919067\ttraining's binary_logloss: 0.112081\tvalid_1's auc: 0.827972\tvalid_1's binary_logloss: 0.137034\n",
      "[23]\ttraining's auc: 0.920926\ttraining's binary_logloss: 0.111149\tvalid_1's auc: 0.827966\tvalid_1's binary_logloss: 0.136982\n",
      "[24]\ttraining's auc: 0.922343\ttraining's binary_logloss: 0.110277\tvalid_1's auc: 0.828121\tvalid_1's binary_logloss: 0.136891\n",
      "[25]\ttraining's auc: 0.925227\ttraining's binary_logloss: 0.10932\tvalid_1's auc: 0.828784\tvalid_1's binary_logloss: 0.13677\n",
      "[26]\ttraining's auc: 0.927099\ttraining's binary_logloss: 0.108532\tvalid_1's auc: 0.828922\tvalid_1's binary_logloss: 0.13673\n",
      "[27]\ttraining's auc: 0.928211\ttraining's binary_logloss: 0.107817\tvalid_1's auc: 0.828914\tvalid_1's binary_logloss: 0.136706\n",
      "[28]\ttraining's auc: 0.930255\ttraining's binary_logloss: 0.107153\tvalid_1's auc: 0.828739\tvalid_1's binary_logloss: 0.136686\n",
      "[29]\ttraining's auc: 0.931505\ttraining's binary_logloss: 0.1065\tvalid_1's auc: 0.82884\tvalid_1's binary_logloss: 0.136682\n",
      "[30]\ttraining's auc: 0.934114\ttraining's binary_logloss: 0.105614\tvalid_1's auc: 0.828438\tvalid_1's binary_logloss: 0.136762\n",
      "[31]\ttraining's auc: 0.935353\ttraining's binary_logloss: 0.104947\tvalid_1's auc: 0.828368\tvalid_1's binary_logloss: 0.136787\n",
      "[32]\ttraining's auc: 0.936424\ttraining's binary_logloss: 0.104357\tvalid_1's auc: 0.82835\tvalid_1's binary_logloss: 0.136781\n",
      "[33]\ttraining's auc: 0.937389\ttraining's binary_logloss: 0.103754\tvalid_1's auc: 0.828078\tvalid_1's binary_logloss: 0.136835\n",
      "[34]\ttraining's auc: 0.938089\ttraining's binary_logloss: 0.103121\tvalid_1's auc: 0.82789\tvalid_1's binary_logloss: 0.136891\n",
      "[35]\ttraining's auc: 0.938895\ttraining's binary_logloss: 0.102602\tvalid_1's auc: 0.827737\tvalid_1's binary_logloss: 0.136945\n",
      "[36]\ttraining's auc: 0.939688\ttraining's binary_logloss: 0.102065\tvalid_1's auc: 0.827934\tvalid_1's binary_logloss: 0.136924\n",
      "[37]\ttraining's auc: 0.940291\ttraining's binary_logloss: 0.101549\tvalid_1's auc: 0.827487\tvalid_1's binary_logloss: 0.137066\n",
      "[38]\ttraining's auc: 0.941191\ttraining's binary_logloss: 0.100976\tvalid_1's auc: 0.827645\tvalid_1's binary_logloss: 0.137073\n",
      "[39]\ttraining's auc: 0.942172\ttraining's binary_logloss: 0.100457\tvalid_1's auc: 0.827608\tvalid_1's binary_logloss: 0.137107\n",
      "[40]\ttraining's auc: 0.942955\ttraining's binary_logloss: 0.0999505\tvalid_1's auc: 0.827498\tvalid_1's binary_logloss: 0.137135\n",
      "[41]\ttraining's auc: 0.94365\ttraining's binary_logloss: 0.0994755\tvalid_1's auc: 0.827267\tvalid_1's binary_logloss: 0.137248\n",
      "[42]\ttraining's auc: 0.944602\ttraining's binary_logloss: 0.0988995\tvalid_1's auc: 0.827242\tvalid_1's binary_logloss: 0.13728\n",
      "[43]\ttraining's auc: 0.945241\ttraining's binary_logloss: 0.0984025\tvalid_1's auc: 0.827239\tvalid_1's binary_logloss: 0.137304\n",
      "[44]\ttraining's auc: 0.945632\ttraining's binary_logloss: 0.0979999\tvalid_1's auc: 0.827294\tvalid_1's binary_logloss: 0.137312\n",
      "[45]\ttraining's auc: 0.946186\ttraining's binary_logloss: 0.0976623\tvalid_1's auc: 0.827094\tvalid_1's binary_logloss: 0.137397\n",
      "[46]\ttraining's auc: 0.946951\ttraining's binary_logloss: 0.0970428\tvalid_1's auc: 0.826805\tvalid_1's binary_logloss: 0.137523\n",
      "[47]\ttraining's auc: 0.947926\ttraining's binary_logloss: 0.0965543\tvalid_1's auc: 0.826725\tvalid_1's binary_logloss: 0.137598\n",
      "[48]\ttraining's auc: 0.948634\ttraining's binary_logloss: 0.0960462\tvalid_1's auc: 0.826743\tvalid_1's binary_logloss: 0.137625\n",
      "[49]\ttraining's auc: 0.949104\ttraining's binary_logloss: 0.0957028\tvalid_1's auc: 0.826504\tvalid_1's binary_logloss: 0.137718\n",
      "[50]\ttraining's auc: 0.950227\ttraining's binary_logloss: 0.0951471\tvalid_1's auc: 0.826419\tvalid_1's binary_logloss: 0.137802\n",
      "[51]\ttraining's auc: 0.950726\ttraining's binary_logloss: 0.094686\tvalid_1's auc: 0.826308\tvalid_1's binary_logloss: 0.137876\n",
      "[52]\ttraining's auc: 0.951116\ttraining's binary_logloss: 0.0942916\tvalid_1's auc: 0.826095\tvalid_1's binary_logloss: 0.137954\n",
      "[53]\ttraining's auc: 0.951793\ttraining's binary_logloss: 0.0938301\tvalid_1's auc: 0.825869\tvalid_1's binary_logloss: 0.138063\n",
      "[54]\ttraining's auc: 0.95266\ttraining's binary_logloss: 0.0932778\tvalid_1's auc: 0.825808\tvalid_1's binary_logloss: 0.138163\n",
      "[55]\ttraining's auc: 0.952944\ttraining's binary_logloss: 0.0929426\tvalid_1's auc: 0.825505\tvalid_1's binary_logloss: 0.138286\n",
      "[56]\ttraining's auc: 0.953565\ttraining's binary_logloss: 0.0925877\tvalid_1's auc: 0.825569\tvalid_1's binary_logloss: 0.138354\n",
      "[57]\ttraining's auc: 0.953946\ttraining's binary_logloss: 0.0921967\tvalid_1's auc: 0.825262\tvalid_1's binary_logloss: 0.138468\n",
      "[58]\ttraining's auc: 0.95441\ttraining's binary_logloss: 0.0917893\tvalid_1's auc: 0.825091\tvalid_1's binary_logloss: 0.138551\n",
      "[59]\ttraining's auc: 0.954526\ttraining's binary_logloss: 0.0915647\tvalid_1's auc: 0.824835\tvalid_1's binary_logloss: 0.138665\n",
      "[60]\ttraining's auc: 0.955089\ttraining's binary_logloss: 0.0911274\tvalid_1's auc: 0.82466\tvalid_1's binary_logloss: 0.138788\n",
      "[61]\ttraining's auc: 0.955936\ttraining's binary_logloss: 0.0905937\tvalid_1's auc: 0.824408\tvalid_1's binary_logloss: 0.138923\n",
      "[62]\ttraining's auc: 0.956122\ttraining's binary_logloss: 0.0902972\tvalid_1's auc: 0.824034\tvalid_1's binary_logloss: 0.139036\n",
      "[63]\ttraining's auc: 0.956337\ttraining's binary_logloss: 0.090077\tvalid_1's auc: 0.823774\tvalid_1's binary_logloss: 0.139163\n",
      "[64]\ttraining's auc: 0.956539\ttraining's binary_logloss: 0.0897788\tvalid_1's auc: 0.823575\tvalid_1's binary_logloss: 0.139259\n",
      "[65]\ttraining's auc: 0.956989\ttraining's binary_logloss: 0.0894349\tvalid_1's auc: 0.82339\tvalid_1's binary_logloss: 0.139394\n",
      "[66]\ttraining's auc: 0.957363\ttraining's binary_logloss: 0.0890671\tvalid_1's auc: 0.822961\tvalid_1's binary_logloss: 0.13955\n",
      "[67]\ttraining's auc: 0.957844\ttraining's binary_logloss: 0.0888509\tvalid_1's auc: 0.822812\tvalid_1's binary_logloss: 0.139656\n",
      "[68]\ttraining's auc: 0.958082\ttraining's binary_logloss: 0.0885565\tvalid_1's auc: 0.822449\tvalid_1's binary_logloss: 0.139796\n",
      "[69]\ttraining's auc: 0.958284\ttraining's binary_logloss: 0.088334\tvalid_1's auc: 0.82217\tvalid_1's binary_logloss: 0.139899\n",
      "[70]\ttraining's auc: 0.959037\ttraining's binary_logloss: 0.0878572\tvalid_1's auc: 0.821967\tvalid_1's binary_logloss: 0.139955\n",
      "[71]\ttraining's auc: 0.959348\ttraining's binary_logloss: 0.0876114\tvalid_1's auc: 0.821741\tvalid_1's binary_logloss: 0.140061\n",
      "[72]\ttraining's auc: 0.959588\ttraining's binary_logloss: 0.0873082\tvalid_1's auc: 0.821439\tvalid_1's binary_logloss: 0.140205\n",
      "[73]\ttraining's auc: 0.959985\ttraining's binary_logloss: 0.0869021\tvalid_1's auc: 0.821185\tvalid_1's binary_logloss: 0.140322\n",
      "[74]\ttraining's auc: 0.96053\ttraining's binary_logloss: 0.0864388\tvalid_1's auc: 0.820971\tvalid_1's binary_logloss: 0.14045\n",
      "[75]\ttraining's auc: 0.960681\ttraining's binary_logloss: 0.0862568\tvalid_1's auc: 0.820868\tvalid_1's binary_logloss: 0.14053\n",
      "[76]\ttraining's auc: 0.960886\ttraining's binary_logloss: 0.0859483\tvalid_1's auc: 0.820783\tvalid_1's binary_logloss: 0.140631\n",
      "[77]\ttraining's auc: 0.961051\ttraining's binary_logloss: 0.085692\tvalid_1's auc: 0.820341\tvalid_1's binary_logloss: 0.140774\n",
      "[78]\ttraining's auc: 0.962001\ttraining's binary_logloss: 0.0851317\tvalid_1's auc: 0.820265\tvalid_1's binary_logloss: 0.140874\n",
      "[79]\ttraining's auc: 0.962093\ttraining's binary_logloss: 0.0849529\tvalid_1's auc: 0.82003\tvalid_1's binary_logloss: 0.141025\n",
      "[80]\ttraining's auc: 0.962495\ttraining's binary_logloss: 0.084653\tvalid_1's auc: 0.819626\tvalid_1's binary_logloss: 0.141183\n",
      "[81]\ttraining's auc: 0.962973\ttraining's binary_logloss: 0.0842686\tvalid_1's auc: 0.819525\tvalid_1's binary_logloss: 0.141255\n",
      "[82]\ttraining's auc: 0.963187\ttraining's binary_logloss: 0.0840658\tvalid_1's auc: 0.819357\tvalid_1's binary_logloss: 0.141339\n",
      "[83]\ttraining's auc: 0.963348\ttraining's binary_logloss: 0.0838287\tvalid_1's auc: 0.819048\tvalid_1's binary_logloss: 0.141478\n",
      "[84]\ttraining's auc: 0.963427\ttraining's binary_logloss: 0.0836507\tvalid_1's auc: 0.819048\tvalid_1's binary_logloss: 0.141565\n",
      "[85]\ttraining's auc: 0.963573\ttraining's binary_logloss: 0.0834155\tvalid_1's auc: 0.818689\tvalid_1's binary_logloss: 0.141708\n",
      "[86]\ttraining's auc: 0.963823\ttraining's binary_logloss: 0.0831046\tvalid_1's auc: 0.818478\tvalid_1's binary_logloss: 0.141785\n",
      "[87]\ttraining's auc: 0.965836\ttraining's binary_logloss: 0.0823004\tvalid_1's auc: 0.818497\tvalid_1's binary_logloss: 0.141808\n",
      "[88]\ttraining's auc: 0.966952\ttraining's binary_logloss: 0.0817931\tvalid_1's auc: 0.818342\tvalid_1's binary_logloss: 0.141889\n",
      "[89]\ttraining's auc: 0.967092\ttraining's binary_logloss: 0.0815713\tvalid_1's auc: 0.8181\tvalid_1's binary_logloss: 0.142006\n",
      "[90]\ttraining's auc: 0.967198\ttraining's binary_logloss: 0.0813748\tvalid_1's auc: 0.817901\tvalid_1's binary_logloss: 0.142144\n",
      "[91]\ttraining's auc: 0.967289\ttraining's binary_logloss: 0.0812003\tvalid_1's auc: 0.817346\tvalid_1's binary_logloss: 0.142344\n",
      "[92]\ttraining's auc: 0.96796\ttraining's binary_logloss: 0.080802\tvalid_1's auc: 0.81704\tvalid_1's binary_logloss: 0.142483\n",
      "[93]\ttraining's auc: 0.968292\ttraining's binary_logloss: 0.0804823\tvalid_1's auc: 0.816645\tvalid_1's binary_logloss: 0.142648\n",
      "[94]\ttraining's auc: 0.968368\ttraining's binary_logloss: 0.0803371\tvalid_1's auc: 0.816138\tvalid_1's binary_logloss: 0.142823\n",
      "[95]\ttraining's auc: 0.968743\ttraining's binary_logloss: 0.0801193\tvalid_1's auc: 0.816263\tvalid_1's binary_logloss: 0.142948\n",
      "[96]\ttraining's auc: 0.969109\ttraining's binary_logloss: 0.0798413\tvalid_1's auc: 0.816315\tvalid_1's binary_logloss: 0.142969\n",
      "[97]\ttraining's auc: 0.969306\ttraining's binary_logloss: 0.079608\tvalid_1's auc: 0.816122\tvalid_1's binary_logloss: 0.143059\n",
      "[98]\ttraining's auc: 0.969377\ttraining's binary_logloss: 0.0794567\tvalid_1's auc: 0.816048\tvalid_1's binary_logloss: 0.143167\n",
      "[99]\ttraining's auc: 0.969468\ttraining's binary_logloss: 0.0793084\tvalid_1's auc: 0.815926\tvalid_1's binary_logloss: 0.143289\n",
      "[100]\ttraining's auc: 0.969748\ttraining's binary_logloss: 0.079001\tvalid_1's auc: 0.815823\tvalid_1's binary_logloss: 0.143422\n",
      "[101]\ttraining's auc: 0.970064\ttraining's binary_logloss: 0.0787195\tvalid_1's auc: 0.815893\tvalid_1's binary_logloss: 0.143488\n",
      "[102]\ttraining's auc: 0.970129\ttraining's binary_logloss: 0.0785741\tvalid_1's auc: 0.815496\tvalid_1's binary_logloss: 0.14364\n",
      "[103]\ttraining's auc: 0.970595\ttraining's binary_logloss: 0.0781652\tvalid_1's auc: 0.815395\tvalid_1's binary_logloss: 0.143719\n",
      "[104]\ttraining's auc: 0.971035\ttraining's binary_logloss: 0.0778012\tvalid_1's auc: 0.815331\tvalid_1's binary_logloss: 0.143819\n",
      "[105]\ttraining's auc: 0.971498\ttraining's binary_logloss: 0.0775089\tvalid_1's auc: 0.815193\tvalid_1's binary_logloss: 0.14392\n",
      "[106]\ttraining's auc: 0.972124\ttraining's binary_logloss: 0.0771079\tvalid_1's auc: 0.815036\tvalid_1's binary_logloss: 0.143998\n",
      "[107]\ttraining's auc: 0.973379\ttraining's binary_logloss: 0.0766171\tvalid_1's auc: 0.815121\tvalid_1's binary_logloss: 0.144021\n",
      "[108]\ttraining's auc: 0.973425\ttraining's binary_logloss: 0.0765044\tvalid_1's auc: 0.814688\tvalid_1's binary_logloss: 0.144179\n",
      "[109]\ttraining's auc: 0.974178\ttraining's binary_logloss: 0.0760609\tvalid_1's auc: 0.814844\tvalid_1's binary_logloss: 0.144264\n",
      "[110]\ttraining's auc: 0.974367\ttraining's binary_logloss: 0.075827\tvalid_1's auc: 0.814674\tvalid_1's binary_logloss: 0.144412\n",
      "[111]\ttraining's auc: 0.974605\ttraining's binary_logloss: 0.0756639\tvalid_1's auc: 0.814799\tvalid_1's binary_logloss: 0.144527\n",
      "[112]\ttraining's auc: 0.974721\ttraining's binary_logloss: 0.075454\tvalid_1's auc: 0.814563\tvalid_1's binary_logloss: 0.144647\n",
      "[113]\ttraining's auc: 0.974798\ttraining's binary_logloss: 0.0752553\tvalid_1's auc: 0.814577\tvalid_1's binary_logloss: 0.144734\n",
      "[114]\ttraining's auc: 0.9753\ttraining's binary_logloss: 0.0748148\tvalid_1's auc: 0.814323\tvalid_1's binary_logloss: 0.144842\n",
      "[115]\ttraining's auc: 0.975775\ttraining's binary_logloss: 0.0744681\tvalid_1's auc: 0.814228\tvalid_1's binary_logloss: 0.144943\n",
      "[116]\ttraining's auc: 0.97602\ttraining's binary_logloss: 0.0741651\tvalid_1's auc: 0.814091\tvalid_1's binary_logloss: 0.145057\n",
      "[117]\ttraining's auc: 0.976611\ttraining's binary_logloss: 0.0738097\tvalid_1's auc: 0.813944\tvalid_1's binary_logloss: 0.145167\n",
      "[118]\ttraining's auc: 0.976702\ttraining's binary_logloss: 0.0736115\tvalid_1's auc: 0.813694\tvalid_1's binary_logloss: 0.145306\n",
      "[119]\ttraining's auc: 0.977356\ttraining's binary_logloss: 0.0732294\tvalid_1's auc: 0.813647\tvalid_1's binary_logloss: 0.145397\n",
      "[120]\ttraining's auc: 0.978021\ttraining's binary_logloss: 0.0727988\tvalid_1's auc: 0.813677\tvalid_1's binary_logloss: 0.145442\n",
      "[121]\ttraining's auc: 0.978473\ttraining's binary_logloss: 0.0724923\tvalid_1's auc: 0.813565\tvalid_1's binary_logloss: 0.145578\n",
      "[122]\ttraining's auc: 0.978703\ttraining's binary_logloss: 0.0722636\tvalid_1's auc: 0.813396\tvalid_1's binary_logloss: 0.14571\n",
      "[123]\ttraining's auc: 0.978738\ttraining's binary_logloss: 0.0721304\tvalid_1's auc: 0.813051\tvalid_1's binary_logloss: 0.145925\n",
      "[124]\ttraining's auc: 0.978969\ttraining's binary_logloss: 0.0718297\tvalid_1's auc: 0.812952\tvalid_1's binary_logloss: 0.145998\n",
      "[125]\ttraining's auc: 0.979179\ttraining's binary_logloss: 0.0715143\tvalid_1's auc: 0.812705\tvalid_1's binary_logloss: 0.14616\n",
      "[126]\ttraining's auc: 0.979451\ttraining's binary_logloss: 0.0712533\tvalid_1's auc: 0.812587\tvalid_1's binary_logloss: 0.146312\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(n_estimators=500)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(n_estimators=500)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(n_estimators=500)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm = LGBMClassifier(n_estimators=500)\n",
    "lgbm.fit(x_train,\n",
    "         y_train,\n",
    "         early_stopping_rounds=100,\n",
    "         eval_metric='auc',\n",
    "         eval_set=[(x_train, y_train), (x_test, y_test)],\n",
    "         verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
